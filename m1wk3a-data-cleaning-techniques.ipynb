{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873e41f9",
   "metadata": {},
   "source": [
    "### Data Cleaning Techniques\n",
    "\n",
    "Data cleaning is an essential part of any data science project. It involves transforming raw data into a format that is more appropriate for analysis by addressing issues such as missing values, incorrect data, duplicate records, and outliers. Proper data cleaning ensures the accuracy and reliability of the analysis, leading to better insights and decision-making.\n",
    "In this note, we’ll cover two key aspects of data cleaning: \n",
    "\n",
    "**1. Handling missing values** \n",
    "\n",
    "**2. Data transformation**\n",
    "\n",
    "\n",
    "#### **1. Handling Missing Values**\n",
    "Missing data is a common issue in datasets. Missing values can arise from various reasons such as data collection errors, data entry mistakes, or system issues. If not handled properly, missing data can lead to biased results or errors in the analysis.\n",
    "\n",
    "**Approaches to Handle Missing Values**\n",
    "\n",
    "There are several ways to handle missing values, depending on the context and the nature of the data:\n",
    "\n",
    "##### a. Remove Missing Data\n",
    "\n",
    "One straightforward method to handle missing values is to remove the rows or columns containing them.\n",
    "\n",
    "•\t**Dropping Rows**: If a dataset has missing values in only a few rows, removing these rows might be a practical solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcef9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ade</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bola</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name   Age   Salary\n",
       "0   Ade  25.0  50000.0\n",
       "1  Bola  30.0      NaN\n",
       "2  Kola   NaN  70000.0\n",
       "3  None  40.0      NaN\n",
       "4   Obi   NaN  65000.0\n",
       "5  None  27.0      NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with missing values\n",
    "data = {'Name': ['Ade', 'Bola', 'Kola', None, 'Obi', None],\n",
    "        'Age': [25, 30, None, 40, None, 27],\n",
    "        'Salary': [50000, None, 70000, None, 65000, None]}\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "#df.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af366988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset:\n",
      "   Name   Age   Salary\n",
      "0   Ade  25.0  50000.0\n",
      "1  Bola  30.0      NaN\n",
      "2  Kola   NaN  70000.0\n",
      "3  None  40.0      NaN\n",
      "4   Obi   NaN  65000.0\n",
      "5  None  27.0      NaN\n",
      "\n",
      "Frequency table for missing Values:\n",
      "Name      2\n",
      "Age       2\n",
      "Salary    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Inspect the data for missing values\n",
    "print(\"Initial Dataset:\")\n",
    "print(df)\n",
    "print(\"\\nFrequency table for missing Values:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1000d4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name   Age   Salary\n",
      "0  Ade  25.0  50000.0\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with any missing values\n",
    "df_clean = df.dropna() # drops rows with missing values \n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e69769b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "\n",
    "# Show first rows\n",
    "print(titanic.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fe67ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic dataset saved as titanic_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "\n",
    "# Save to CSV\n",
    "titanic.to_csv(\"datasets/titanic/titanic.csv\", index=False)\n",
    "\n",
    "print(\"Titanic dataset saved as titanic_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe0c8d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset\n",
    "train = pd.read_csv(\"datasets/titanic/train.csv\")\n",
    "test = pd.read_csv(\"datasets/titanic/test.csv\")\n",
    "\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dae3a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
      "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  \n",
      "0      man        True  NaN  Southampton    no  False  \n",
      "1    woman       False    C    Cherbourg   yes  False  \n",
      "2    woman       False  NaN  Southampton   yes   True  \n",
      "3    woman       False    C  Southampton   yes  False  \n",
      "4      man        True  NaN  Southampton    no   True  \n",
      "..     ...         ...  ...          ...   ...    ...  \n",
      "886    man        True  NaN  Southampton    no   True  \n",
      "887  woman       False    B  Southampton   yes   True  \n",
      "888  woman       False  NaN  Southampton    no  False  \n",
      "889    man        True    C    Cherbourg   yes   True  \n",
      "890    man        True  NaN   Queenstown    no   True  \n",
      "\n",
      "[891 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reading a CSV file with missing values\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('datasets/titanic/titanic.csv')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9adb210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency table for missing Values in titanic data:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Inspect the data for missing values\n",
    "#print(\"Initial Dataset:\")\n",
    "#print(df1)\n",
    "print(\"\\nFrequency table for missing Values in titanic data:\")\n",
    "print(df1.isna().sum()) # code to know number of missing values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33baa283",
   "metadata": {},
   "source": [
    "•\t**Dropping Columns:** If a column has too many missing values and is not crucial for analysis, it might be better to drop the entire column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0881d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns with any missing values\n",
    "df_clean = df.dropna(axis=1) # drops columns with missing value\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0252e5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex  sibsp  parch     fare   class    who  \\\n",
      "0           0       3    male      1      0   7.2500   Third    man   \n",
      "1           1       1  female      1      0  71.2833   First  woman   \n",
      "2           1       3  female      0      0   7.9250   Third  woman   \n",
      "3           1       1  female      1      0  53.1000   First  woman   \n",
      "4           0       3    male      0      0   8.0500   Third    man   \n",
      "..        ...     ...     ...    ...    ...      ...     ...    ...   \n",
      "886         0       2    male      0      0  13.0000  Second    man   \n",
      "887         1       1  female      0      0  30.0000   First  woman   \n",
      "888         0       3  female      1      2  23.4500   Third  woman   \n",
      "889         1       1    male      0      0  30.0000   First    man   \n",
      "890         0       3    male      0      0   7.7500   Third    man   \n",
      "\n",
      "     adult_male alive  alone  \n",
      "0          True    no  False  \n",
      "1         False   yes  False  \n",
      "2         False   yes   True  \n",
      "3         False   yes  False  \n",
      "4          True    no   True  \n",
      "..          ...   ...    ...  \n",
      "886        True    no   True  \n",
      "887       False   yes   True  \n",
      "888       False    no  False  \n",
      "889        True   yes   True  \n",
      "890        True    no   True  \n",
      "\n",
      "[891 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns with any missing values\n",
    "df1_clean = df1.dropna(axis=1) # drops columns with missing value\n",
    "print(df1_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d43f5",
   "metadata": {},
   "source": [
    "##### b. Imputation (Filling Missing Data)\n",
    "Instead of dropping data, missing values can be filled or “imputed” with plausible values. Some common imputation techniques include:\n",
    "\n",
    "**1.\tFill with a constant value:** You can replace missing values with a specific constant like 0 or Unknown (for categorical data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c86120e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary\n",
      "0   Ade  25.0  50000.0\n",
      "1  Bola  30.0      0.0\n",
      "2  Kola   0.0  70000.0\n",
      "3     0  40.0      0.0\n",
      "4   Obi   0.0  65000.0\n",
      "5     0  27.0      0.0\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values with a specific constant (e.g., 0)\n",
    "df_filled = df.fillna(0)\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b23db",
   "metadata": {},
   "source": [
    "**2. Fill with the mean/median/mode:** For numerical data, missing values can be filled with statistical measures like the mean, median, or mode of the respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0a3ac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary\n",
      "0   Ade  25.0  50000.0\n",
      "1  Bola  30.0      NaN\n",
      "2  Kola  30.5  70000.0\n",
      "3  None  40.0      NaN\n",
      "4   Obi  30.5  65000.0\n",
      "5  None  27.0      NaN\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values with the mean of the column\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "228d723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age        Salary\n",
      "0   Ade  25.0  50000.000000\n",
      "1  Bola  30.0  61666.666667\n",
      "2  Kola  30.5  70000.000000\n",
      "3  None  40.0  61666.666667\n",
      "4   Obi  30.5  65000.000000\n",
      "5  None  27.0  61666.666667\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values with the mean of the column\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].mean())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb74ee3",
   "metadata": {},
   "source": [
    "**3.\tForward fill or backward fill:** For time series data, missing values can be filled using the last known value (forward fill) or the next known value (backward fill)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6efb4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age        Salary\n",
      "0   Ade  25.0  50000.000000\n",
      "1  Bola  30.0  61666.666667\n",
      "2  Kola  30.5  70000.000000\n",
      "3  Kola  40.0  61666.666667\n",
      "4   Obi  30.5  65000.000000\n",
      "5   Obi  27.0  61666.666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DR  AJAO\\AppData\\Local\\Temp\\ipykernel_16476\\2825471144.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled_ffill = df.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Forward fill\n",
    "df_filled_ffill = df.fillna(method='ffill')\n",
    "print(df_filled_ffill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c04134aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olu</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bola</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age   Salary\n",
       "0      Olu  45.0  50000.0\n",
       "1     Bola  37.0  40000.0\n",
       "2  Charles   NaN  60000.0\n",
       "3     None  40.0      NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data with missing values\n",
    "data2 = {'Name': ['Olu', 'Bola', 'Charles', None],\n",
    "        'Age': [45, 37, None, 40],\n",
    "        'Salary': [50000, 40000, 60000, None]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8247ad",
   "metadata": {},
   "source": [
    "##### c. Interpolate Missing Values\n",
    "Interpolation is a more advanced technique where missing values are estimated based on patterns in the data. Pandas provides an **`interpolate()`** function for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f79965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age   Salary\n",
      "0      Olu  45.0  50000.0\n",
      "1     Bola  37.0  40000.0\n",
      "2  Charles  38.5  60000.0\n",
      "3     None  40.0  60000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DR  AJAO\\AppData\\Local\\Temp\\ipykernel_16476\\1871875028.py:2: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df2_interpolated = df2.interpolate()\n"
     ]
    }
   ],
   "source": [
    "# Interpolating missing values\n",
    "df2_interpolated = df2.interpolate()\n",
    "print(df2_interpolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a4956",
   "metadata": {},
   "source": [
    "This method is particularly useful for filling gaps in time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a0bf1",
   "metadata": {},
   "source": [
    "##### d. Flag and Model Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a9b9d",
   "metadata": {},
   "source": [
    "In cases where data is missing in a non-random way (i.e., it could affect the outcome of the analysis), it might be useful to:\n",
    "\n",
    "**1.\tFlag the missing values:** Create a new column that flags whether the data was missing or not.\n",
    "\n",
    "**2.\tModel missing data:** If there’s a pattern to missing data, you can use machine learning models to predict and fill missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d500f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age        Salary  Age_missing\n",
      "0   Ade  25.0  50000.000000        False\n",
      "1  Bola  30.0  61666.666667        False\n",
      "2  Kola  30.5  70000.000000        False\n",
      "3  None  40.0  61666.666667        False\n",
      "4   Obi  30.5  65000.000000        False\n",
      "5  None  27.0  61666.666667        False\n"
     ]
    }
   ],
   "source": [
    "# Flagging missing values\n",
    "df['Age_missing'] = df['Age'].isnull()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022ab5e",
   "metadata": {},
   "source": [
    "### 2. Data Transformation\n",
    "Data transformation involves changing the format, structure, or values of the data to make it more suitable for analysis. It can include scaling, encoding, or normalizing the data to make it compatible with machine learning algorithms.\n",
    "##### a. Scaling Data\n",
    "In some cases, the range of data values can differ widely, which may cause issues in algorithms that are sensitive to the scale of input data (e.g., linear regression, k-nearest neighbors, or neural networks). Scaling ensures that each feature contributes equally to the analysis.\n",
    "\n",
    "**•\tStandardization (Z-score normalization):** Rescales data to have a mean of 0 and a standard deviation of 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebc72ea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Example DataFrame\u001b[39;00m\n\u001b[32m      3\u001b[39m data = {\u001b[33m'\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m25\u001b[39m, \u001b[32m30\u001b[39m, \u001b[32m35\u001b[39m, \u001b[32m40\u001b[39m],\n\u001b[32m      4\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSalary\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m50000\u001b[39m, \u001b[32m60000\u001b[39m, \u001b[32m70000\u001b[39m, \u001b[32m80000\u001b[39m]}\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Example DataFrame\n",
    "data = {'Age': [25, 30, 35, 40],\n",
    "        'Salary': [50000, 60000, 70000, 80000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "print(scaled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea99eacd",
   "metadata": {},
   "source": [
    "**•\tMin-Max Scaling (Normalization):** Rescales data to a fixed range, typically [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d6a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age    Salary\n",
      "0  0.000000  0.000000\n",
      "1  0.333333  0.333333\n",
      "2  0.666667  0.666667\n",
      "3  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=df.columns)\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903fc9e",
   "metadata": {},
   "source": [
    "##### b. Encoding Categorical Variables\n",
    "Many machine learning algorithms require numerical inputs. Hence, categorical data must be converted into numerical values. This can be done using techniques like:\n",
    "\n",
    "**•\tLabel Encoding:** Each unique category is assigned an integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ca66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City  City_encoded\n",
      "0         Lagos             2\n",
      "1  Port Harcout             3\n",
      "2        Ibadan             0\n",
      "3        Kaduna             1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data with categorical values\n",
    "df = pd.DataFrame({'City': ['Lagos', 'Port Harcout', 'Ibadan', 'Kaduna']})\n",
    "\n",
    "# Encoding the 'City' column\n",
    "encoder = LabelEncoder()\n",
    "df['City_encoded'] = encoder.fit_transform(df['City']) # this can be referred to as code book for city\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb8c71",
   "metadata": {},
   "source": [
    "##### c. Log Transformation\n",
    "Log transformation is useful when dealing with highly skewed data. By applying the logarithm to the data, you can reduce the skewness and bring the data closer to a normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66960d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary  Salary_log\n",
      "0   Ade  25.0  50000.0   10.819778\n",
      "1  Bola  30.0      NaN         NaN\n",
      "2  Kola   NaN  70000.0   11.156251\n",
      "3  None  40.0      NaN         NaN\n",
      "4   Obi   NaN  65000.0   11.082143\n",
      "5  None  27.0      NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Applying log transformation to 'Salary' column\n",
    "df['Salary_log'] = np.log(df['Salary'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b19d7",
   "metadata": {},
   "source": [
    "##### d. Binning/Discretization\n",
    "Binning or discretization involves converting continuous data into discrete intervals or bins. This can simplify models and help detect patterns in certain types of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ba478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary  Salary_log    Age_group\n",
      "0   Ade  25.0  50000.0   10.819778  Young Adult\n",
      "1  Bola  30.0      NaN         NaN  Young Adult\n",
      "2  Kola   NaN  70000.0   11.156251          NaN\n",
      "3  None  40.0      NaN         NaN        Adult\n",
      "4   Obi   NaN  65000.0   11.082143          NaN\n",
      "5  None  27.0      NaN         NaN  Young Adult\n"
     ]
    }
   ],
   "source": [
    "# Binning the 'Age' column into categories\n",
    "interval = [0, 18, 35, 60]\n",
    "category = ['Child', 'Young Adult', 'Adult']\n",
    "df['Age_group'] = pd.cut(df['Age'], bins=interval, labels=category)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a16aa",
   "metadata": {},
   "source": [
    "Here's a breakdown of the code:\n",
    "\n",
    "1. **Define Bins**:\n",
    "   ```python\n",
    "   bins = [0, 18, 35, 60]\n",
    "   ```\n",
    "   - This line defines the age ranges to group (or \"bin\") the values in the `Age` column.\n",
    "   - The intervals are:\n",
    "     - `0-18`\n",
    "     - `18-35`\n",
    "     - `35-60`\n",
    "\n",
    "2. **Define Labels**:\n",
    "   ```python\n",
    "   category = ['Child', 'Young Adult', 'Adult']\n",
    "   ```\n",
    "   - This list defines the category labels corresponding to each age range.\n",
    "   - Each label will be assigned based on which bin a particular age falls into:\n",
    "     - `0-18` will be labeled as `Child`\n",
    "     - `18-35` will be labeled as `Young Adult`\n",
    "     - `35-60` will be labeled as `Adult`\n",
    "\n",
    "3. **Binning the 'Age' Column**:\n",
    "   ```python\n",
    "   df['Age_group'] = pd.cut(df['Age'], bins=interval, labels=category)\n",
    "   ```\n",
    "   - This line creates a new column, `Age_group`, in the `df` DataFrame.\n",
    "   - `pd.cut()` is used to segment and categorize the `Age` column into the specified bins.\n",
    "   - The new `Age_group` column will contain the corresponding label for each age based on the bin it falls into."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
