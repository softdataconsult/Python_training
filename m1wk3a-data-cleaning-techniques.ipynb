{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873e41f9",
   "metadata": {},
   "source": [
    "### Data Cleaning Techniques\n",
    "\n",
    "Data cleaning is an essential part of any data science project. It involves transforming raw data into a format that is more appropriate for analysis by addressing issues such as missing values, incorrect data, duplicate records, and outliers. Proper data cleaning ensures the accuracy and reliability of the analysis, leading to better insights and decision-making.\n",
    "In this note, we’ll cover two key aspects of data cleaning: \n",
    "\n",
    "**1. Handling missing values** \n",
    "\n",
    "**2. Data transformation**\n",
    "\n",
    "\n",
    "#### **1. Handling Missing Values**\n",
    "Missing data is a common issue in datasets. Missing values can arise from various reasons such as data collection errors, data entry mistakes, or system issues. If not handled properly, missing data can lead to biased results or errors in the analysis.\n",
    "\n",
    "**Approaches to Handle Missing Values**\n",
    "\n",
    "There are several ways to handle missing values, depending on the context and the nature of the data:\n",
    "\n",
    "##### a. Remove Missing Data\n",
    "\n",
    "One straightforward method to handle missing values is to remove the rows or columns containing them.\n",
    "\n",
    "•\t**Dropping Rows**: If a dataset has missing values in only a few rows, removing these rows might be a practical solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcef9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ade</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bola</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name   Age   Salary\n",
       "0   Ade  25.0  50000.0\n",
       "1  Bola  30.0      NaN\n",
       "2  Kola   NaN  70000.0\n",
       "3  None  40.0      NaN\n",
       "4   Obi   NaN  65000.0\n",
       "5  None  27.0      NaN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with missing values\n",
    "data = {'Name': ['Ade', 'Bola', 'Kola', None, 'Obi', None],\n",
    "        'Age': [25, 30, None, 40, None, 27],\n",
    "        'Salary': [50000, None, 70000, None, 65000, None]}\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "#df.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af366988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset:\n",
      "   Name   Age   Salary\n",
      "0   Ade  25.0  50000.0\n",
      "1  Bola  30.0      NaN\n",
      "2  Kola   NaN  70000.0\n",
      "3  None  40.0      NaN\n",
      "4   Obi   NaN  65000.0\n",
      "5  None  27.0      NaN\n",
      "\n",
      "Frequency table for missing Values:\n",
      "Name      2\n",
      "Age       2\n",
      "Salary    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Inspect the data for missing values\n",
    "print(\"Initial Dataset:\")\n",
    "print(df)\n",
    "print(\"\\nFrequency table for missing Values:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1000d4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name   Age   Salary\n",
      "0  Ade  25.0  50000.0\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with any missing values\n",
    "df_clean = df.dropna() # drops rows with missing values \n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dae3a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0            892         0       3   \n",
      "1            893         1       3   \n",
      "2            894         0       2   \n",
      "3            895         0       3   \n",
      "4            896         1       3   \n",
      "..           ...       ...     ...   \n",
      "413         1305         0       3   \n",
      "414         1306         1       1   \n",
      "415         1307         0       3   \n",
      "416         1308         0       3   \n",
      "417         1309         0       3   \n",
      "\n",
      "                                             Name     Sex   Age  SibSp  Parch  \\\n",
      "0                                Kelly, Mr. James    male  34.5      0      0   \n",
      "1                Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                       Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                                Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4    Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "..                                            ...     ...   ...    ...    ...   \n",
      "413                            Spector, Mr. Woolf    male   NaN      0      0   \n",
      "414                  Oliva y Ocana, Dona. Fermina  female  39.0      0      0   \n",
      "415                  Saether, Mr. Simon Sivertsen    male  38.5      0      0   \n",
      "416                           Ware, Mr. Frederick    male   NaN      0      0   \n",
      "417                      Peter, Master. Michael J    male   NaN      1      1   \n",
      "\n",
      "                 Ticket      Fare Cabin Embarked  \n",
      "0                330911    7.8292   NaN        Q  \n",
      "1                363272    7.0000   NaN        S  \n",
      "2                240276    9.6875   NaN        Q  \n",
      "3                315154    8.6625   NaN        S  \n",
      "4               3101298   12.2875   NaN        S  \n",
      "..                  ...       ...   ...      ...  \n",
      "413           A.5. 3236    8.0500   NaN        S  \n",
      "414            PC 17758  108.9000  C105        C  \n",
      "415  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
      "416              359309    8.0500   NaN        S  \n",
      "417                2668   22.3583   NaN        C  \n",
      "\n",
      "[418 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reading a CSV file with missing values\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('titanic.csv')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9adb210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency table for missing Values in titanic data:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Inspect the data for missing values\n",
    "#print(\"Initial Dataset:\")\n",
    "#print(df1)\n",
    "print(\"\\nFrequency table for missing Values in titanic data:\")\n",
    "print(df1.isna().sum()) # code to know number of missing values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33baa283",
   "metadata": {},
   "source": [
    "•\t**Dropping Columns:** If a column has too many missing values and is not crucial for analysis, it might be better to drop the entire column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0881d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns with any missing values\n",
    "df_clean = df.dropna(axis=1) # drops columns with missing value\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0252e5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0            892         0       3   \n",
      "1            893         1       3   \n",
      "2            894         0       2   \n",
      "3            895         0       3   \n",
      "4            896         1       3   \n",
      "..           ...       ...     ...   \n",
      "413         1305         0       3   \n",
      "414         1306         1       1   \n",
      "415         1307         0       3   \n",
      "416         1308         0       3   \n",
      "417         1309         0       3   \n",
      "\n",
      "                                             Name     Sex  SibSp  Parch  \\\n",
      "0                                Kelly, Mr. James    male      0      0   \n",
      "1                Wilkes, Mrs. James (Ellen Needs)  female      1      0   \n",
      "2                       Myles, Mr. Thomas Francis    male      0      0   \n",
      "3                                Wirz, Mr. Albert    male      0      0   \n",
      "4    Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female      1      1   \n",
      "..                                            ...     ...    ...    ...   \n",
      "413                            Spector, Mr. Woolf    male      0      0   \n",
      "414                  Oliva y Ocana, Dona. Fermina  female      0      0   \n",
      "415                  Saether, Mr. Simon Sivertsen    male      0      0   \n",
      "416                           Ware, Mr. Frederick    male      0      0   \n",
      "417                      Peter, Master. Michael J    male      1      1   \n",
      "\n",
      "                 Ticket Embarked  \n",
      "0                330911        Q  \n",
      "1                363272        S  \n",
      "2                240276        Q  \n",
      "3                315154        S  \n",
      "4               3101298        S  \n",
      "..                  ...      ...  \n",
      "413           A.5. 3236        S  \n",
      "414            PC 17758        C  \n",
      "415  SOTON/O.Q. 3101262        S  \n",
      "416              359309        S  \n",
      "417                2668        C  \n",
      "\n",
      "[418 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns with any missing values\n",
    "df1_clean = df1.dropna(axis=1) # drops columns with missing value\n",
    "print(df1_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d43f5",
   "metadata": {},
   "source": [
    "##### b. Imputation (Filling Missing Data)\n",
    "Instead of dropping data, missing values can be filled or “imputed” with plausible values. Some common imputation techniques include:\n",
    "\n",
    "**1.\tFill with a constant value:** You can replace missing values with a specific constant like 0 or Unknown (for categorical data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c86120e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values with a specific constant (e.g., 0)\n",
    "df_filled = df.fillna(0)\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b23db",
   "metadata": {},
   "source": [
    "**2. Fill with the mean/median/mode:** For numerical data, missing values can be filled with statistical measures like the mean, median, or mode of the respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0a3ac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary\n",
      "0   Ade  25.0  50000.0\n",
      "1  Bola  30.0      NaN\n",
      "2  Kola  30.5  70000.0\n",
      "3  None  40.0      NaN\n",
      "4   Obi  30.5  65000.0\n",
      "5  None  27.0      NaN\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values with the mean of the column\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "228d723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age        Salary\n",
      "0   Ade  25.0  50000.000000\n",
      "1  Bola  30.0  61666.666667\n",
      "2  Kola  30.5  70000.000000\n",
      "3  None  40.0  61666.666667\n",
      "4   Obi  30.5  65000.000000\n",
      "5  None  27.0  61666.666667\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values with the mean of the column\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].mean())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb74ee3",
   "metadata": {},
   "source": [
    "**3.\tForward fill or backward fill:** For time series data, missing values can be filled using the last known value (forward fill) or the next known value (backward fill)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6efb4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age        Salary\n",
      "0   Ade  25.0  50000.000000\n",
      "1  Bola  30.0  61666.666667\n",
      "2  Kola  30.5  70000.000000\n",
      "3  Kola  40.0  61666.666667\n",
      "4   Obi  30.5  65000.000000\n",
      "5   Obi  27.0  61666.666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16088\\2825471144.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled_ffill = df.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Forward fill\n",
    "df_filled_ffill = df.fillna(method='ffill')\n",
    "print(df_filled_ffill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c04134aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olu</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bola</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age   Salary\n",
       "0      Olu  45.0  50000.0\n",
       "1     Bola  37.0  40000.0\n",
       "2  Charles   NaN  60000.0\n",
       "3     None  40.0      NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data with missing values\n",
    "data2 = {'Name': ['Olu', 'Bola', 'Charles', None],\n",
    "        'Age': [45, 37, None, 40],\n",
    "        'Salary': [50000, 40000, 60000, None]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8247ad",
   "metadata": {},
   "source": [
    "##### c. Interpolate Missing Values\n",
    "Interpolation is a more advanced technique where missing values are estimated based on patterns in the data. Pandas provides an **`interpolate()`** function for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6f79965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age   Salary\n",
      "0      Olu  45.0  50000.0\n",
      "1     Bola  37.0  40000.0\n",
      "2  Charles  38.5  60000.0\n",
      "3     None  40.0  60000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16088\\1871875028.py:2: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df2_interpolated = df2.interpolate()\n"
     ]
    }
   ],
   "source": [
    "# Interpolating missing values\n",
    "df2_interpolated = df2.interpolate()\n",
    "print(df2_interpolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a4956",
   "metadata": {},
   "source": [
    "This method is particularly useful for filling gaps in time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a0bf1",
   "metadata": {},
   "source": [
    "##### d. Flag and Model Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a9b9d",
   "metadata": {},
   "source": [
    "In cases where data is missing in a non-random way (i.e., it could affect the outcome of the analysis), it might be useful to:\n",
    "\n",
    "**1.\tFlag the missing values:** Create a new column that flags whether the data was missing or not.\n",
    "\n",
    "**2.\tModel missing data:** If there’s a pattern to missing data, you can use machine learning models to predict and fill missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d500f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age        Salary  Age_missing  missing_age\n",
      "0   Ade  25.0  50000.000000        False        False\n",
      "1  Bola  30.0  61666.666667        False        False\n",
      "2  Kola  30.5  70000.000000        False        False\n",
      "3  None  40.0  61666.666667        False        False\n",
      "4   Obi  30.5  65000.000000        False        False\n",
      "5  None  27.0  61666.666667        False        False\n"
     ]
    }
   ],
   "source": [
    "# Flagging missing values\n",
    "df['Age_missing'] = df['Age'].isnull()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022ab5e",
   "metadata": {},
   "source": [
    "### 2. Data Transformation\n",
    "Data transformation involves changing the format, structure, or values of the data to make it more suitable for analysis. It can include scaling, encoding, or normalizing the data to make it compatible with machine learning algorithms.\n",
    "##### a. Scaling Data\n",
    "In some cases, the range of data values can differ widely, which may cause issues in algorithms that are sensitive to the scale of input data (e.g., linear regression, k-nearest neighbors, or neural networks). Scaling ensures that each feature contributes equally to the analysis.\n",
    "\n",
    "**•\tStandardization (Z-score normalization):** Rescales data to have a mean of 0 and a standard deviation of 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebc72ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age    Salary\n",
      "0 -1.341641 -1.341641\n",
      "1 -0.447214 -0.447214\n",
      "2  0.447214  0.447214\n",
      "3  1.341641  1.341641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Example DataFrame\n",
    "data = {'Age': [25, 30, 35, 40],\n",
    "        'Salary': [50000, 60000, 70000, 80000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "print(scaled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea99eacd",
   "metadata": {},
   "source": [
    "**•\tMin-Max Scaling (Normalization):** Rescales data to a fixed range, typically [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e0d6a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age    Salary\n",
      "0  0.000000  0.000000\n",
      "1  0.333333  0.333333\n",
      "2  0.666667  0.666667\n",
      "3  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=df.columns)\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903fc9e",
   "metadata": {},
   "source": [
    "##### b. Encoding Categorical Variables\n",
    "Many machine learning algorithms require numerical inputs. Hence, categorical data must be converted into numerical values. This can be done using techniques like:\n",
    "\n",
    "**•\tLabel Encoding:** Each unique category is assigned an integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "132ca66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City  City_encoded\n",
      "0         Lagos             2\n",
      "1  Port Harcout             3\n",
      "2        Ibadan             0\n",
      "3        Kaduna             1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data with categorical values\n",
    "df = pd.DataFrame({'City': ['Lagos', 'Port Harcout', 'Ibadan', 'Kaduna']})\n",
    "\n",
    "# Encoding the 'City' column\n",
    "encoder = LabelEncoder()\n",
    "df['City_encoded'] = encoder.fit_transform(df['City']) # this can be referred to as code book for city\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb8c71",
   "metadata": {},
   "source": [
    "##### c. Log Transformation\n",
    "Log transformation is useful when dealing with highly skewed data. By applying the logarithm to the data, you can reduce the skewness and bring the data closer to a normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66960d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary  Salary_log\n",
      "0   Ade  25.0  50000.0   10.819778\n",
      "1  Bola  30.0      NaN         NaN\n",
      "2  Kola   NaN  70000.0   11.156251\n",
      "3  None  40.0      NaN         NaN\n",
      "4   Obi   NaN  65000.0   11.082143\n",
      "5  None  27.0      NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Applying log transformation to 'Salary' column\n",
    "df['Salary_log'] = np.log(df['Salary'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b19d7",
   "metadata": {},
   "source": [
    "##### d. Binning/Discretization\n",
    "Binning or discretization involves converting continuous data into discrete intervals or bins. This can simplify models and help detect patterns in certain types of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f5ba478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary  Salary_log    Age_group\n",
      "0   Ade  25.0  50000.0   10.819778  Young Adult\n",
      "1  Bola  30.0      NaN         NaN  Young Adult\n",
      "2  Kola   NaN  70000.0   11.156251          NaN\n",
      "3  None  40.0      NaN         NaN        Adult\n",
      "4   Obi   NaN  65000.0   11.082143          NaN\n",
      "5  None  27.0      NaN         NaN  Young Adult\n"
     ]
    }
   ],
   "source": [
    "# Binning the 'Age' column into categories\n",
    "interval = [0, 18, 35, 60]\n",
    "category = ['Child', 'Young Adult', 'Adult']\n",
    "df['Age_group'] = pd.cut(df['Age'], bins=interval, labels=category)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a16aa",
   "metadata": {},
   "source": [
    "Here's a breakdown of the code:\n",
    "\n",
    "1. **Define Bins**:\n",
    "   ```python\n",
    "   bins = [0, 18, 35, 60]\n",
    "   ```\n",
    "   - This line defines the age ranges to group (or \"bin\") the values in the `Age` column.\n",
    "   - The intervals are:\n",
    "     - `0-18`\n",
    "     - `18-35`\n",
    "     - `35-60`\n",
    "\n",
    "2. **Define Labels**:\n",
    "   ```python\n",
    "   category = ['Child', 'Young Adult', 'Adult']\n",
    "   ```\n",
    "   - This list defines the category labels corresponding to each age range.\n",
    "   - Each label will be assigned based on which bin a particular age falls into:\n",
    "     - `0-18` will be labeled as `Child`\n",
    "     - `18-35` will be labeled as `Young Adult`\n",
    "     - `35-60` will be labeled as `Adult`\n",
    "\n",
    "3. **Binning the 'Age' Column**:\n",
    "   ```python\n",
    "   df['Age_group'] = pd.cut(df['Age'], bins=interval, labels=category)\n",
    "   ```\n",
    "   - This line creates a new column, `Age_group`, in the `df` DataFrame.\n",
    "   - `pd.cut()` is used to segment and categorize the `Age` column into the specified bins.\n",
    "   - The new `Age_group` column will contain the corresponding label for each age based on the bin it falls into."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
