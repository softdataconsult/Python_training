{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e627522",
   "metadata": {},
   "source": [
    "## **Inferential Statistics**\n",
    "\n",
    "**Inferential statistics** allows us to make predictions or inferences about a population based on a sample of data. While descriptive statistics summarize the data, inferential statistics help us draw conclusions about a larger group from the observed data. Two key components of inferential statistics are **hypothesis testing** and **confidence intervals**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Hypothesis Testing**\n",
    "\n",
    "**Hypothesis testing** is a statistical method used to make decisions or inferences about population parameters based on sample data. It allows us to test assumptions or claims and evaluate whether the data supports or rejects those claims.\n",
    "\n",
    "#### a) **Key Terms in Hypothesis Testing**\n",
    "- **Null Hypothesis $( H_0 )$**: A statement that there is no effect or no difference. It is the hypothesis that is initially assumed to be true.\n",
    "- **Alternative Hypothesis $( H_1 )$ or $( H_a )$**: A statement that contradicts the null hypothesis. It indicates the presence of an effect or difference.\n",
    "- **Test Statistic**: A value calculated from the sample data that is used to make a decision about the null hypothesis. Examples include the \\( t \\)-statistic and \\( z \\)-statistic.\n",
    "- **P-value**: The probability of obtaining a test statistic at least as extreme as the one observed, assuming the null hypothesis is true. A low p-value suggests that the null hypothesis is unlikely.\n",
    "- **Significance Level $( \\alpha )$**: The threshold for rejecting the null hypothesis. Common significance levels are 0.05 (5%) or 0.01 (1%). If the p-value is less than $( \\alpha )$, the null hypothesis is rejected.\n",
    "- **Type I Error**: Rejecting the null hypothesis when it is actually true (false positive).\n",
    "- **Type II Error**: Failing to reject the null hypothesis when it is actually false (false negative).\n",
    "\n",
    "#### b) **Steps in Hypothesis Testing**\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis $( H_0 )$: There is no significant difference or effect.\n",
    "   - Alternative Hypothesis $( H_1 )$: There is a significant difference or effect.\n",
    "\n",
    "2. **Choose a Significance Level $( \\alpha )$**: Typically, $( \\alpha = 0.05 )$ is used, meaning there’s a 5% risk of rejecting the null hypothesis when it is true.\n",
    "\n",
    "3. **Select the Appropriate Test**: Depending on the data, you might use a:\n",
    "   - **t-test**: To compare the means of two groups.\n",
    "   - **z-test**: For large samples when population variance is known.\n",
    "   - **ANOVA (Analysis of Variance)**: To compare means of three or more groups.\n",
    "   - **Chi-square test**: For categorical data to compare observed frequencies with expected frequencies.\n",
    "\n",
    "4. **Calculate the Test Statistic**: Based on the sample data, compute the value of the test statistic (e.g., \\( t \\)-statistic or \\( z \\)-statistic).\n",
    "\n",
    "5. **Compute the P-value**: The p-value indicates the probability of observing the test statistic under the null hypothesis. \n",
    "If the p-value is smaller than $( \\alpha )$, reject the null hypothesis.\n",
    "\n",
    "6. **Make a Decision** (Decision Rule):\n",
    "   - **Reject $( H_0 )$**: If the p-value is less or equal to the significance level ($( \\alpha )$).\n",
    "   - **Fail to reject $( H_0 )$**: If the p-value is greater than $( \\alpha )$.\n",
    "\n",
    "#### c) **Examples of Hypothesis Testing**\n",
    "\n",
    "**Example 1: One-sample t-test**\n",
    "Suppose we want to test whether the average height of adult men in a city is 175 cm. We collect a sample of 30 men and calculate their average height as 172 cm with a standard deviation of 5 cm. We test the null hypothesis $( H_0: \\mu = 175 )$ cm against the alternative hypothesis $( H_1: \\mu \\neq 175 )$ cm using a t-test.\n",
    "\n",
    "- Null Hypothesis $( H_0 )$: The mean height is 175 cm.\n",
    "- Alternative Hypothesis $( H_1)$: The mean height is not 175 cm.\n",
    "- We calculate the t-statistic and compare it with the critical value based on the significance level (e.g., $( \\alpha = 0.05 )$.\n",
    "\n",
    "**Example 2: Two-sample t-test**\n",
    "In another scenario, we might compare the means of two groups, such as the test scores of students who took an online course versus those who attended in person. Here, we would use a two-sample t-test to determine if there’s a significant difference between the two group means.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Confidence Intervals**\n",
    "\n",
    "A **confidence interval** is a range of values used to estimate the true value of a population parameter (such as the population mean) with a certain level of confidence. It provides an interval estimate rather than a point estimate and helps quantify the uncertainty associated with the sample statistic.\n",
    "\n",
    "#### a) **Key Concepts of Confidence Intervals**\n",
    "- **Confidence Level**: The probability that the confidence interval contains the true population parameter. Common confidence levels are 90%, 95%, and 99%. A 95% confidence level means that if we take 100 different samples, approximately 95 of the corresponding confidence intervals will contain the true population parameter.\n",
    "- **Margin of Error**: The amount added and subtracted from the sample mean to create the confidence interval. It depends on the standard error and the confidence level.\n",
    "\n",
    "#### b) **Formula for Confidence Interval for the Mean**\n",
    "\n",
    "For a sample mean, the confidence interval can be calculated as:\n",
    "\n",
    "$$\\text{CI} = \\bar{x} \\pm z* \\times \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "Where:\n",
    "- $( \\bar{x})$ is the sample mean.\n",
    "- $( z^* )$ is the critical value from the standard normal distribution corresponding to the desired confidence level (e.g., for a 95% confidence interval, $( z* = 1.96 )$.\n",
    "- $( \\sigma )$ is the population standard deviation (or the sample standard deviation if $( \\sigma )$ is unknown).\n",
    "- \\( n \\) is the sample size.\n",
    "\n",
    "If the population standard deviation is unknown and the sample size is small, we use the t-distribution instead of the z-distribution.\n",
    "\n",
    "#### c) **Example of a Confidence Interval**\n",
    "\n",
    "**Example**:\n",
    "Suppose you survey 100 people and find that their average income is 50,000 dollars with a standard deviation of 10,000. You want to construct a $95\\%$ confidence interval for the true average income of the population.\n",
    "\n",
    "- Sample mean $( \\bar{x} = 50,000 )$\n",
    "- Sample standard deviation \\( s = 10,000 \\)\n",
    "- Sample size \\( n = 100 \\)\n",
    "- For a $95\\%$ confidence level, the critical value $( z* = 1.96 )$\n",
    "\n",
    "The margin of error is:\n",
    "\n",
    "$$\\text{Margin of Error} =   z* \\times \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "$$\\text{Margin of Error} = 1.96 \\times \\frac{10,000}{\\sqrt{100}} = 1.96 \\times 1,000 = 1,960$$\n",
    "\n",
    "\n",
    "Thus, the 95% confidence interval is:\n",
    "\n",
    "$$(50,000 - 1,960, 50,000 + 1,960) = (48,040, 51,960)$$\n",
    "\n",
    "\n",
    "This means we are $(95\\%)$ confident that the true average income lies between 48,040 and 51,960.\n",
    "\n",
    "#### d) **Interpretation of Confidence Intervals**\n",
    "\n",
    "- If the confidence interval for the mean does not include a particular value (e.g., zero in regression analysis), we can conclude that there is a statistically significant difference at the given confidence level.\n",
    "- A **wider confidence interval** indicates more uncertainty, while a **narrower confidence interval** indicates more precision in the estimate.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "**Hypothesis Testing**:\n",
    "- Helps determine whether to reject or fail to reject a claim about the population based on sample data.\n",
    "- Involves key steps such as stating hypotheses, calculating a test statistic, and making a decision based on the p-value.\n",
    "\n",
    "**Confidence Intervals**:\n",
    "- Provide a range of values likely to contain the population parameter.\n",
    "- Give an indication of the reliability of the estimate, with a higher confidence level resulting in a wider interval.\n",
    "\n",
    "Both hypothesis testing and confidence intervals are foundational tools in inferential statistics, enabling data scientists to make informed decisions about populations from samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53bc4813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67.64052346 54.00157208 59.78737984 72.40893199 68.6755799  40.2272212\n",
      " 59.50088418 48.48642792 48.96781148 54.10598502 51.44043571 64.54273507\n",
      " 57.61037725 51.21675016 54.43863233 53.33674327 64.94079073 47.94841736\n",
      " 53.13067702 41.45904261 24.47010184 56.53618595 58.64436199 42.5783498\n",
      " 72.69754624 35.45634325 50.45758517 48.1281615  65.32779214 64.6935877\n",
      " 51.54947426 53.7816252  41.12214252 30.19203532 46.52087851 51.56348969\n",
      " 62.30290681 62.02379849 46.12673183 46.97697249 39.51447035 35.79982063\n",
      " 32.93729809 69.50775395 44.90347818 45.61925698 37.4720464  57.77490356\n",
      " 33.86102152 47.8725972  41.04533439 53.86902498 44.89194862 38.19367816\n",
      " 49.71817772 54.28331871 50.66517222 53.02471898 43.65677906 46.37258834\n",
      " 43.27539552 46.40446838 41.86853718 32.73717398 51.77426142 45.98219064\n",
      " 33.69801653 54.62782256 40.92701636 50.51945396 57.29090562 51.28982911\n",
      " 61.39400685 37.6517418  54.02341641 43.15189909 41.29202851 44.21150335\n",
      " 46.88447468 50.56165342 38.34850159 59.00826487 54.6566244  34.63756314\n",
      " 64.88252194 68.95889176 61.78779571 48.20075164 39.29247378 60.54451727\n",
      " 45.96823053 62.2244507  52.08274978 59.76639036 53.56366397 57.06573168\n",
      " 50.10500021 67.85870494 51.26912093 54.01989363]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Example Dataset\n",
    "np.random.seed(0)\n",
    "sample_data = np.random.normal(loc=50, scale=10, size=100)\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee1cd2",
   "metadata": {},
   "source": [
    "### Code Breakdown\n",
    "\n",
    "#### 1. **`np.random.seed(0)`**\n",
    "   - Sets the random number generator's seed to `0`.\n",
    "   - Ensures that the random numbers generated are reproducible. If you rerun the code with the same seed, you will get the same output.\n",
    "\n",
    "#### 2. **`np.random.normal(loc=50, scale=10, size=100)`**\n",
    "   - Generates a sample of random numbers from a **normal (Gaussian) distribution**.\n",
    "   - Parameters:\n",
    "     - `loc=50`: The mean (center) of the distribution.\n",
    "     - `scale=10`: The standard deviation (spread) of the distribution.\n",
    "     - `size=100`: The number of random numbers to generate.\n",
    "   - Output:\n",
    "     - An array of 100 random numbers drawn from the specified normal distribution.\n",
    "\n",
    "#### 3. **`sample_data`**\n",
    "   - Stores the generated random numbers in an array.\n",
    "\n",
    "#### 4. **`print(sample_data)`**\n",
    "   - Prints the array of random numbers to the console.\n",
    "\n",
    "### Purpose\n",
    "This code is often used in data analysis or machine learning scenarios to simulate or test algorithms on synthetic data, particularly when working with normally distributed data.\n",
    "\n",
    "### Example Output\n",
    "When you run the code, you might see something like this (exact values depend on the random seed and distribution parameters):\n",
    "\n",
    "```plaintext\n",
    "[67.64052346 54.00157208 59.78737984 72.40893199 68.6755799  ...\n",
    "```\n",
    "\n",
    "This array contains 100 numbers with a mean around 50 and a standard deviation of about 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20323e01",
   "metadata": {},
   "source": [
    "### 1. Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fde59d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval for the mean: (np.float64(48.58814820996595), np.float64(52.60801210072373))\n"
     ]
    }
   ],
   "source": [
    "## Example: 95% confidence interval for the mean\n",
    "mean = np.mean(sample_data)\n",
    "std_error = stats.sem(sample_data)\n",
    "confidence_level = 0.95\n",
    "ci = stats.t.interval(confidence_level, len(sample_data)-1, loc=mean, scale=std_error)\n",
    "print(f\"95% Confidence Interval for the mean: {ci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe56d79",
   "metadata": {},
   "source": [
    "This code calculates the **95% confidence interval (CI)** for the mean of the dataset using the **t-distribution**, which is appropriate for small samples or when the population standard deviation is unknown.\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### 1. **`mean = np.mean(sample_data)`**\n",
    "   - Calculates the **sample mean** of the data in `sample_data`.\n",
    "   - `np.mean` computes the average of all the values in the dataset.\n",
    "\n",
    "#### 2. **`std_error = stats.sem(sample_data)`**\n",
    "   - Calculates the **standard error of the mean** (SEM).\n",
    "   - SEM is the standard deviation of the sample mean distribution, computed as:\n",
    "     $$\n",
    "     \\text{SEM} = \\frac{\\text{Standard Deviation}}{\\sqrt{\\text{Sample Size}}}\n",
    "     $$\n",
    "\n",
    "#### 3. **`confidence_level = 0.95`**\n",
    "   - Sets the **confidence level** at 95%.\n",
    "   - This means there is a 95% chance that the true population mean lies within the computed interval.\n",
    "\n",
    "#### 4. **`stats.t.interval(confidence_level, len(sample_data)-1, loc=mean, scale=std_error)`**\n",
    "   - Uses the **t-distribution** to compute the confidence interval for the mean.\n",
    "   - Parameters:\n",
    "     - `confidence_level`: The desired confidence level (e.g., 0.95 for 95% CI).\n",
    "     - `len(sample_data)-1`: The degrees of freedom, equal to the sample size minus 1, i.e. n-1\n",
    "     - `loc=mean`: The sample mean, which is the center of the confidence interval.\n",
    "     - `scale=std_error`: The standard error of the mean.\n",
    "\n",
    "   - Returns a tuple `(lower_bound, upper_bound)` representing the confidence interval.\n",
    "\n",
    "#### 5. **`print(f\"95% Confidence Interval for the mean: {ci}\")`**\n",
    "   - Prints the computed confidence interval in a formatted string.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example\n",
    "If `sample_data` is the array generated in your earlier code, the output might look something like this:\n",
    "\n",
    "```plaintext\n",
    "95% Confidence Interval for the mean: (48.58814820996595, 52.60801210072373\n",
    "```\n",
    "\n",
    "### Interpretation\n",
    "- The **95% confidence interval** means:\n",
    "  - There is a 95% chance that the **true population mean** lies between `48.59` and `52.61`.\n",
    "  - The interval width depends on the variability in the data (standard deviation), the sample size, and the chosen confidence level.\n",
    "\n",
    "### Why Use the t-distribution?\n",
    "- The **t-distribution** accounts for the additional uncertainty in estimating the population standard deviation when working with a sample. It is more conservative than the normal distribution, especially for smaller sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb7ae2",
   "metadata": {},
   "source": [
    "### 2. Hypothesis Testing (One-Sample t-Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69de6df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-sample t-test: t-statistic = -1.38, p-value = 0.17\n"
     ]
    }
   ],
   "source": [
    "## Example: Test if the sample mean is significantly different from 52\n",
    "hypothesized_mean = 52\n",
    "t_stat, p_value = stats.ttest_1samp(sample_data, hypothesized_mean)\n",
    "print(f\"One-sample t-test: t-statistic = {t_stat:.2f}, p-value = {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48284a8",
   "metadata": {},
   "source": [
    "This code performs a **one-sample t-test** to determine if the mean of the sample (`sample_data`) is significantly different from a **hypothesized population mean** (`hypothesized_mean`).\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### 1. **`hypothesized_mean = 52`**\n",
    "   - Sets the hypothesized population mean to `52`.\n",
    "   - This is the value you are testing the sample mean against.\n",
    "\n",
    "#### 2. **`stats.ttest_1samp(sample_data, hypothesized_mean)`**\n",
    "   - Performs a **one-sample t-test**.\n",
    "   - The one-sample t-test compares the sample mean to the hypothesized mean and tests whether the difference is statistically significant.\n",
    "   - Parameters:\n",
    "     - `sample_data`: The array of sample data.\n",
    "     - `hypothesized_mean`: The mean to compare the sample mean against.\n",
    "   - Returns:\n",
    "     - `t_stat`: The t-statistic, a measure of how far the sample mean is from the hypothesized mean in units of standard error.\n",
    "     - `p_value`: The p-value, which indicates the probability of observing the test statistic (or one more extreme) under the null hypothesis.\n",
    "\n",
    "#### 3. **`print(f\"One-sample t-test: t-statistic = {t_stat:.2f}, p-value = {p_value:.2f}\")`**\n",
    "   - Prints the results of the t-test:\n",
    "     - `t_stat`: Formatted to two decimal places.\n",
    "     - `p_value`: Formatted to two decimal places.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example\n",
    "If you run the code, the output might look like this:\n",
    "\n",
    "```plaintext\n",
    "One-sample t-test: t-statistic = -1.38, p-value = 0.17\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "#### 1. **`t_stat`**\n",
    "   - The t-statistic is a measure of the difference between the sample mean and the hypothesized mean, relative to the standard error.\n",
    "   - A larger absolute value of `t_stat` indicates a more significant difference.\n",
    "\n",
    "#### 2. **`p_value`**\n",
    "   - The p-value represents the probability of obtaining a result as extreme as the observed one under the null hypothesis (that the sample mean equals the hypothesized mean).\n",
    "   - **Significance Threshold**:\n",
    "     - If `p_value < 0.05` (common threshold), the difference is **statistically significant**, and you reject the null hypothesis.\n",
    "     - If `p_value >= 0.05`, you fail to reject the null hypothesis.\n",
    "\n",
    "#### Example Interpretation\n",
    "- **t-statistic = -1.38**: The sample mean is 1.38 standard errors below the hypothesized mean.\n",
    "- **p-value = 0.17**: Since the p-value is not less than 0.05, the difference between the sample mean and the hypothesized mean is not statistically significant. \n",
    "  - You would conclude that the sample mean is not likely to be different from 52.\n",
    "\n",
    "---\n",
    "\n",
    "### Use Case\n",
    "One-sample t-tests are useful in scenarios such as:\n",
    "- Checking if a treatment group’s average differs from a known population average.\n",
    "- Comparing a new product’s performance to a benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200f645",
   "metadata": {},
   "source": [
    "### 3. Two-Sample t-Test (Independent Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd20ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test: t-statistic = 2.96, p-value = 0.00\n"
     ]
    }
   ],
   "source": [
    "## Example: Test if two independent samples have significantly different means\n",
    "np.random.seed(10)\n",
    "sample1 = np.random.normal(52, 10, 100)\n",
    "sample2 = np.random.normal(48, 10, 100)\n",
    "t_stat, p_value = stats.ttest_ind(sample1, sample2)\n",
    "print(f\"Two-sample t-test: t-statistic = {t_stat:.2f}, p-value = {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3713226c",
   "metadata": {},
   "source": [
    "This code performs a **two-sample t-test** to determine if two independent samples, `sample1` and `sample2`, have significantly different means.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### 1. **`sample1 = np.random.normal(52, 10, 100)`**\n",
    "   - Generates `sample1`, a random sample of size 100 drawn from a normal distribution with:\n",
    "     - Mean (`loc`) = 52.\n",
    "     - Standard deviation (`scale`) = 10.\n",
    "     - Sample size (`size`) = 100.\n",
    "\n",
    "#### 2. **`sample2 = np.random.normal(48, 10, 100)`**\n",
    "   - Similarly, generates `sample2` from a normal distribution with:\n",
    "     - Mean (`loc`) = 48.\n",
    "     - Standard deviation (`scale`) = 10.\n",
    "     - Sample size (`size`) = 100.\n",
    "\n",
    "#### 3. **`stats.ttest_ind(sample1, sample2)`**\n",
    "   - Performs an **independent two-sample t-test** to compare the means of two independent samples.\n",
    "   - Parameters:\n",
    "     - `sample1`: The first sample data.\n",
    "     - `sample2`: The second sample data.\n",
    "   - Returns:\n",
    "     - `t_stat`: The t-statistic, which quantifies the difference between the means relative to the variability in the data.\n",
    "     - `p_value`: The p-value, indicating the probability of observing the test statistic under the null hypothesis (no difference in means).\n",
    "\n",
    "#### 4. **`print(f\"Two-sample t-test: t-statistic = {t_stat:.2f}, p-value = {p_value:.2f}\")`**\n",
    "   - Prints the results of the t-test:\n",
    "     - `t_stat`: The test statistic, formatted to two decimal places.\n",
    "     - `p_value`: The p-value, formatted to two decimal places.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example\n",
    "If you run the code, the output might look like this:\n",
    "\n",
    "```plaintext\n",
    "Two-sample t-test: t-statistic = 2.96, p-value = 0.00\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "#### 1. **`t_stat`**\n",
    "   - A measure of the difference between the two sample means, scaled by the variability in the samples.\n",
    "   - A larger absolute value indicates a more significant difference.\n",
    "\n",
    "#### 2. **`p_value`**\n",
    "   - The p-value indicates the probability of obtaining a result as extreme as the observed one under the null hypothesis (that the two sample means are equal).\n",
    "   - **Significance Threshold**:\n",
    "     - If `p_value < 0.05`, the means are significantly different, and you reject the null hypothesis.\n",
    "     - If `p_value >= 0.05`, you fail to reject the null hypothesis.\n",
    "\n",
    "#### Example Interpretation\n",
    "- **t-statistic = 2.96**: The difference between the sample means is significant relative to the data's variability.\n",
    "- **p-value = 0.00**: Since the p-value is less than 0.05, the means of `sample1` and `sample2` are **statistically different**.\n",
    "\n",
    "---\n",
    "\n",
    "### Assumptions of the Test\n",
    "1. The two samples are independent.\n",
    "2. The data in each sample are normally distributed.\n",
    "3. The variances of the two populations are approximately equal (can be relaxed by using `stats.ttest_ind(..., equal_var=False)`).\n",
    "\n",
    "---\n",
    "\n",
    "### Use Case\n",
    "Two-sample t-tests are commonly used to:\n",
    "- Compare the performance of two independent groups (e.g., control vs. treatment).\n",
    "- Test the effect of two different conditions in an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ed7ca",
   "metadata": {},
   "source": [
    "### 4. Paired Sample t-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52bbecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired sample t-test: t-statistic = 2.11, p-value = 0.04\n"
     ]
    }
   ],
   "source": [
    "## Example: Test if the means of two related samples differ significantly\n",
    "np.random.seed(10)\n",
    "before_treatment = np.random.normal(50, 10, 30) \n",
    "after_treatment = before_treatment + np.random.normal(-2, 5, 30)  # Simulating effect of treatment\n",
    "t_stat, p_value = stats.ttest_rel(before_treatment, after_treatment)\n",
    "print(f\"Paired sample t-test: t-statistic = {t_stat:.2f}, p-value = {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3ab62",
   "metadata": {},
   "source": [
    "This code performs a **paired sample t-test**, which is used to compare the means of two related samples to determine if their difference is statistically significant. This is often applied in \"before-and-after\" scenarios or when measurements are taken from the same subjects under two conditions.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### 1. **`before_treatment = np.random.normal(50, 10, 30)`**\n",
    "   - Generates the `before_treatment` data, a sample of size 30 drawn from a normal distribution with:\n",
    "     - Mean (`loc`) = 50.\n",
    "     - Standard deviation (`scale`) = 10.\n",
    "\n",
    "#### 2. **`after_treatment = before_treatment + np.random.normal(-2, 5, 30)`**\n",
    "   - Simulates the `after_treatment` data by adding an effect of treatment:\n",
    "     - A random noise term is drawn from a normal distribution with:\n",
    "       - Mean (`loc`) = -2 (indicating an average reduction due to treatment).\n",
    "       - Standard deviation (`scale`) = 5 (simulating variability in the effect).\n",
    "   - This models how the treatment influences the `before_treatment` values.\n",
    "\n",
    "#### 3. **`stats.ttest_rel(before_treatment, after_treatment)`**\n",
    "   - Performs a **paired t-test** to test whether the mean difference between the two paired samples is significantly different from zero.\n",
    "   - Parameters:\n",
    "     - `before_treatment`: The sample data before the treatment.\n",
    "     - `after_treatment`: The paired sample data after the treatment.\n",
    "   - Returns:\n",
    "     - `t_stat`: The t-statistic, which measures the size of the difference relative to the variability in the paired differences.\n",
    "     - `p_value`: The p-value, which indicates the probability of observing the test statistic under the null hypothesis (no mean difference).\n",
    "\n",
    "#### 4. **`print(f\"Paired sample t-test: t-statistic = {t_stat:.2f}, p-value = {p_value:.2f}\")`**\n",
    "   - Prints the test results:\n",
    "     - `t_stat`: Formatted to two decimal places.\n",
    "     - `p_value`: Formatted to two decimal places.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example\n",
    "If you run the code, the output might look like this:\n",
    "\n",
    "```plaintext\n",
    "Paired sample t-test: t-statistic = 2.11, p-value = 0.04\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "#### 1. **`t_stat`**\n",
    "   - A negative t-statistic suggests that the mean of `after_treatment` is lower than the mean of `before_treatment`.\n",
    "\n",
    "#### 2. **`p_value`**\n",
    "   - The p-value indicates the probability of observing such a difference (or a more extreme one) under the null hypothesis (no difference between the paired means).\n",
    "   - **Significance Threshold**:\n",
    "     - If `p_value < 0.05`, the mean difference is statistically significant, and you reject the null hypothesis.\n",
    "     - If `p_value >= 0.05`, you fail to reject the null hypothesis.\n",
    "\n",
    "#### Example Interpretation\n",
    "- **t-statistic = -3.25**: The difference in means (before vs. after) is significant and leans toward a decrease in the mean after treatment.\n",
    "- **p-value = 0.003**: Since the p-value is less than 0.05, the decrease in the mean due to treatment is **statistically significant**.\n",
    "\n",
    "---\n",
    "\n",
    "### Assumptions of the Test\n",
    "1. The pairs are dependent (e.g., measurements on the same individuals or subjects).\n",
    "2. The differences between pairs are normally distributed (especially important for small samples).\n",
    "\n",
    "---\n",
    "\n",
    "### Use Case\n",
    "Paired t-tests are commonly used in:\n",
    "- Pre-post studies (e.g., before and after a treatment or intervention).\n",
    "- Studies measuring subjects under two different but related conditions.\n",
    "- Comparing scores of the same individuals in two testing situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8ba28",
   "metadata": {},
   "source": [
    "### 5. Chi-Square Test for Independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a05800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square test: chi2-statistic = 15.04, p-value = 0.00\n"
     ]
    }
   ],
   "source": [
    "## Example: Test for independence in a contingency table\n",
    "observed = np.array([[30, 10], [20, 40]])\n",
    "chi2_stat, p_value, _, _ = stats.chi2_contingency(observed)\n",
    "print(f\"Chi-square test: chi2-statistic = {chi2_stat:.2f}, p-value = {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18476e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30, 10],\n",
       "       [20, 40]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f36ec",
   "metadata": {},
   "source": [
    "This code performs a **Chi-square test for independence**, which evaluates whether there is a significant association between two categorical variables based on observed frequencies in a contingency table.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### 1. **`observed = np.array([[30, 10], [20, 40]])`**\n",
    "   - Defines the observed frequencies in a contingency table:\n",
    "     ```\n",
    "     [[30, 10],  # First row of observed counts\n",
    "      [20, 40]]  # Second row of observed counts\n",
    "     ```\n",
    "   - Each cell represents the frequency count for a specific combination of two categorical variables (e.g., Group × Outcome).\n",
    "\n",
    "#### 2. **`stats.chi2_contingency(observed)`**\n",
    "   - Performs the Chi-square test for independence.\n",
    "   - Parameters:\n",
    "     - `observed`: The contingency table of observed frequencies.\n",
    "   - Returns:\n",
    "     - `chi2_stat`: The Chi-square test statistic.\n",
    "     - `p_value`: The p-value indicating the likelihood of observing the data under the null hypothesis.\n",
    "     - `_`: The degrees of freedom (not used in this example).\n",
    "     - `_`: The expected frequencies table (not used in this example).\n",
    "\n",
    "#### 3. **`print(f\"Chi-square test: chi2-statistic = {chi2_stat:.2f}, p-value = {p_value:.2f}\")`**\n",
    "   - Prints the test results:\n",
    "     - `chi2_stat`: The Chi-square statistic, formatted to two decimal places.\n",
    "     - `p_value`: The p-value, formatted to two decimal places.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example\n",
    "If you run the code, the output might look like this:\n",
    "\n",
    "```plaintext\n",
    "Chi-square test: chi2-statistic = 15.04, p-value = 0.00\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "#### 1. **`chi2_stat`**\n",
    "   - A measure of the difference between the observed and expected frequencies under the null hypothesis (independence of variables).\n",
    "   - A larger value indicates a greater discrepancy between observed and expected frequencies.\n",
    "\n",
    "#### 2. **`p_value`**\n",
    "   - The p-value indicates the probability of observing the data (or something more extreme) if the null hypothesis is true.\n",
    "   - **Significance Threshold**:\n",
    "     - If `p_value < 0.05`, you reject the null hypothesis and conclude that the variables are significantly associated.\n",
    "     - If `p_value >= 0.05`, you fail to reject the null hypothesis, suggesting the variables are independent.\n",
    "\n",
    "#### Example Interpretation\n",
    "- **Chi-square statistic = 15.50**: Indicates a substantial difference between observed and expected frequencies.\n",
    "- **p-value = 0.00**: Since the p-value is less than 0.05, the variables are **not independent** and have a statistically significant association.\n",
    "\n",
    "---\n",
    "\n",
    "### Assumptions of the Test\n",
    "1. The data in the contingency table are counts (frequencies).\n",
    "2. Observations are independent of each other.\n",
    "3. The expected frequency in each cell should generally be 5 or more (to ensure validity).\n",
    "\n",
    "---\n",
    "\n",
    "### Use Case\n",
    "Chi-square tests for independence are commonly used to:\n",
    "- Analyze the relationship between two categorical variables (e.g., gender and preference for a product).\n",
    "- Test for associations in survey data or experimental studies involving categorical outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db066e5",
   "metadata": {},
   "source": [
    "### 6. Analysis of Variance (ANOVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8040f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       values    group\n",
      "0   42.876093  Group 1\n",
      "1   57.537664  Group 1\n",
      "2   49.554969  Group 1\n",
      "3   54.518123  Group 1\n",
      "4   63.451017  Group 1\n",
      "..        ...      ...\n",
      "85  62.078001  Group 3\n",
      "86  38.128847  Group 3\n",
      "87  67.219651  Group 3\n",
      "88  63.487506  Group 3\n",
      "89  56.613817  Group 3\n",
      "\n",
      "[90 rows x 2 columns]\n",
      "One-way ANOVA: F-statistic = 4.43, p-value = 0.01\n"
     ]
    }
   ],
   "source": [
    "## Example: One-way ANOVA to test if means of multiple groups are significantly different\n",
    "np.random.seed(13)\n",
    "group1 = np.random.normal(50, 10, 30)\n",
    "group2 = np.random.normal(55, 10, 30)\n",
    "group3 = np.random.normal(60, 10, 30)\n",
    "data = pd.DataFrame({\"values\": np.concatenate([group1, group2, group3]),\n",
    "                     \"group\": [\"Group 1\"]*30 + [\"Group 2\"]*30 + [\"Group 3\"]*30})\n",
    "print(data)\n",
    "anova_result = stats.f_oneway(group1, group2, group3)\n",
    "print(f\"One-way ANOVA: F-statistic = {anova_result.statistic:.2f}, p-value = {anova_result.pvalue:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b0462",
   "metadata": {},
   "source": [
    "This code performs a **One-Way ANOVA (Analysis of Variance)**, which is used to test if the means of three or more independent groups are significantly different.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### 1. **`np.random.seed(10)`**\n",
    "   - Sets the random seed for reproducibility so that the random numbers generated remain the same on each execution.\n",
    "\n",
    "#### 2. **`group1`, `group2`, `group3`**\n",
    "   - Simulates data for three independent groups, each containing 30 samples drawn from normal distributions with:\n",
    "     - **`group1`:** Mean = 50, SD = 10.\n",
    "     - **`group2`:** Mean = 55, SD = 10.\n",
    "     - **`group3`:** Mean = 60, SD = 10.\n",
    "\n",
    "#### 3. **`data`**\n",
    "   - Combines all group data into a single **DataFrame** for display purposes.\n",
    "   - Columns:\n",
    "     - `\"values\"`: Contains the combined data from all groups.\n",
    "     - `\"group\"`: Labels each data point with its respective group name.\n",
    "\n",
    "#### 4. **`stats.f_oneway(group1, group2, group3)`**\n",
    "   - Performs a One-Way ANOVA to test the null hypothesis:\n",
    "     - H₀: All group means are equal.\n",
    "     - H₁: At least one group mean is different.\n",
    "   - Parameters:\n",
    "     - `group1, group2, group3`: The independent group samples.\n",
    "   - Returns:\n",
    "     - `statistic`: The F-statistic, which measures the ratio of between-group variance to within-group variance.\n",
    "     - `pvalue`: The p-value, which indicates the likelihood of observing the data if the null hypothesis is true.\n",
    "\n",
    "#### 5. **`print(f\"One-way ANOVA: F-statistic = {anova_result.statistic:.2f}, p-value = {anova_result.pvalue:.2f}\")`**\n",
    "   - Prints the results of the ANOVA test:\n",
    "     - **F-statistic**: Formatted to two decimal places.\n",
    "     - **p-value**: Formatted to two decimal places.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example\n",
    "\n",
    "If you run the code, the output might look like this:\n",
    "\n",
    "```plaintext\n",
    "One-way ANOVA: F-statistic = 4.43, p-value = 0.01\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "#### 1. **F-statistic**\n",
    "   - Measures the ratio of between-group variance to within-group variance.\n",
    "   - A higher F-statistic indicates a larger difference between group means relative to the variability within groups.\n",
    "\n",
    "#### 2. **p-value**\n",
    "   - The p-value tests the null hypothesis that all group means are equal.\n",
    "   - **Significance Threshold**:\n",
    "     - If `p-value < 0.05`, reject the null hypothesis and conclude that at least one group mean is significantly different.\n",
    "     - If `p-value >= 0.05`, fail to reject the null hypothesis, suggesting no significant difference between group means.\n",
    "\n",
    "#### Example Interpretation\n",
    "- **F-statistic = 4.15**: Indicates a significant difference in group means relative to within-group variability.\n",
    "- **p-value = 0.02**: Since the p-value is less than 0.05, reject the null hypothesis and conclude that at least one group mean is significantly different.\n",
    "\n",
    "---\n",
    "\n",
    "### Assumptions of One-Way ANOVA\n",
    "1. **Independence**: Observations in each group are independent.\n",
    "2. **Normality**: The data in each group should be approximately normally distributed.\n",
    "3. **Homogeneity of Variances**: The variances of the groups should be approximately equal.\n",
    "\n",
    "---\n",
    "\n",
    "### Use Case\n",
    "One-Way ANOVA is commonly used in:\n",
    "- Comparing test scores of students from different teaching methods.\n",
    "- Analyzing the effectiveness of different treatments in medical studies.\n",
    "- Evaluating the performance of multiple groups in experimental settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e345bf",
   "metadata": {},
   "source": [
    "### 7. Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de37495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: correlation coefficient = 0.88, p-value = 0.00\n"
     ]
    }
   ],
   "source": [
    "## Example: Pearson correlation between two continuous variables\n",
    "np.random.seed(13)\n",
    "x = np.random.normal(50, 10, 100)\n",
    "y = 0.8 * x + np.random.normal(0, 5, 100)  # y is correlated with x\n",
    "corr_coeff, p_value = stats.pearsonr(x, y)\n",
    "print(f\"Pearson correlation: correlation coefficient = {corr_coeff:.2f}, p-value = {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73758856",
   "metadata": {},
   "source": [
    "This code calculates the **Pearson correlation coefficient** between two variables, \\( x \\) and \\( y \\), to measure the strength and direction of their linear relationship.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### 1. **Simulating Data**\n",
    "- `x = np.random.normal(50, 10, 100)`\n",
    "  - Generates 100 random numbers from a normal distribution with a mean of 50 and standard deviation of 10.\n",
    "  - Represents the independent variable \\( x \\).\n",
    "\n",
    "- `y = 0.8 * x + np.random.normal(0, 5, 100)`\n",
    "  - Constructs \\( y \\) as a linear function of \\( x \\) with some random noise added.\n",
    "  - The coefficient \\( 0.8 \\) determines the strength of the relationship between \\( x \\) and \\( y \\), while the noise term `np.random.normal(0, 5, 100)` introduces variability to simulate realistic data.\n",
    "\n",
    "#### 2. **Pearson Correlation**\n",
    "- `stats.pearsonr(x, y)`\n",
    "  - Computes the Pearson correlation coefficient (\\( r \\)) and the associated p-value:\n",
    "    - **`corr_coeff`** (\\( r \\)): Measures the strength and direction of the linear relationship between \\( x \\) and \\( y \\). \n",
    "      - Values range from:\n",
    "        - \\( -1 \\): Perfect negative correlation.\n",
    "        - \\( 0 \\): No correlation.\n",
    "        - \\( +1 \\): Perfect positive correlation.\n",
    "    - **`p_value`**: Tests the null hypothesis ($( H_0 $)): No linear correlation between \\( x \\) and \\( y \\).\n",
    "      - **If `p_value < 0.05`**, the correlation is statistically significant.\n",
    "\n",
    "#### 3. **Output**\n",
    "- `print(f\"Pearson correlation: correlation coefficient = {corr_coeff:.2f}, p-value = {p_value:.2f}\")`\n",
    "  - Displays the Pearson correlation coefficient and the p-value, both formatted to two decimal places.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example\n",
    "\n",
    "If you run the code, the output might look like:\n",
    "\n",
    "```plaintext\n",
    "Pearson correlation: correlation coefficient = 0.88, p-value = 0.00\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "#### 1. **Correlation Coefficient (\\( r \\))**\n",
    "- **0.85**: Indicates a strong positive linear relationship between \\( x \\) and \\( y \\).\n",
    "  - Positive values (\\( r > 0 \\)) indicate that as \\( x \\) increases, \\( y \\) also increases.\n",
    "  - Negative values (\\( r < 0 \\)) indicate that as \\( x \\) increases, \\( y \\) decreases.\n",
    "\n",
    "#### 2. **p-value**\n",
    "- **0.00**: Since the p-value is less than 0.05, the correlation is statistically significant, meaning there is strong evidence against the null hypothesis ($( H_0 )$) of no correlation.\n",
    "\n",
    "---\n",
    "\n",
    "### Use Case\n",
    "Pearson correlation is widely used to:\n",
    "- Measure the strength of linear relationships in fields like economics, biology, and psychology.\n",
    "- Check assumptions before linear regression analysis.\n",
    "- Analyze the association between two continuous variables, e.g., height and weight, or temperature and sales.\n",
    "\n",
    "---\n",
    "\n",
    "### Assumptions of Pearson Correlation\n",
    "1. **Linearity**: The relationship between \\( x \\) and \\( y \\) is linear.\n",
    "2. **Normality**: Both variables are normally distributed.\n",
    "3. **Homoscedasticity**: The variability of \\( y \\) should be constant across \\( x \\)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474634c5",
   "metadata": {},
   "source": [
    "### 8. Z-Test for Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9166ac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions Z-test: z-statistic = 0.73, p-value = 0.47\n"
     ]
    }
   ],
   "source": [
    "## Example: Z-test for comparing two proportions\n",
    "count = np.array([40, 35])    # e.g., 40 successes in sample 1 and 35 in sample 2\n",
    "nobs = np.array([100, 100])   # Sample sizes of 100 each\n",
    "z_stat, p_value = proportions_ztest(count, nobs)\n",
    "print(f\"Proportions Z-test: z-statistic = {z_stat:.2f}, p-value = {p_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624cf65",
   "metadata": {},
   "source": [
    "This code performs a **two-proportion Z-test**, which tests whether the proportions of a certain outcome (e.g., success) are significantly different between two independent groups.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### 1. **`count` and `nobs`**\n",
    "- `count = np.array([40, 35])`:\n",
    "  - Represents the number of successes in each group. \n",
    "  - Example: In sample 1, 40 successes; in sample 2, 35 successes.\n",
    "\n",
    "- `nobs = np.array([100, 100])`:\n",
    "  - Represents the sample sizes for each group.\n",
    "  - Example: Each sample contains 100 observations.\n",
    "\n",
    "#### 2. **`proportions_ztest`**\n",
    "- **Function**: `statsmodels.stats.proportion.proportions_ztest(count, nobs)`\n",
    "  - Performs the Z-test for proportions.\n",
    "  - **Parameters**:\n",
    "    - `count`: The number of successes in each sample.\n",
    "    - `nobs`: The total number of observations in each sample.\n",
    "  - **Returns**:\n",
    "    - `z_stat`: The Z-statistic for the test.\n",
    "      - Measures how far the observed difference in proportions is from 0 (the null hypothesis), in units of standard error.\n",
    "    - `p_value`: The p-value for the test.\n",
    "      - Tests the null hypothesis $( H_0 )$: The proportions are equal.\n",
    "\n",
    "#### 3. **`print`**\n",
    "- `print(f\"Proportions Z-test: z-statistic = {z_stat:.2f}, p-value = {p_value:.2f}\")`\n",
    "  - Prints the Z-statistic and p-value, formatted to two decimal places.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example\n",
    "\n",
    "If you run the code, the output might look like:\n",
    "\n",
    "```plaintext\n",
    "Proportions Z-test: z-statistic = 0.73, p-value = 0.47\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "#### 1. **Z-statistic**\n",
    "- **Z-statistic = 0.73**: Indicates how many standard deviations the observed difference in proportions is from 0.\n",
    "  - Positive values: Sample 1's proportion is larger.\n",
    "  - Negative values: Sample 2's proportion is larger.\n",
    "\n",
    "#### 2. **p-value**\n",
    "- **p-value = 0.47**: Tests the null hypothesis $( H_0 )$: The proportions are equal.\n",
    "  - If $( \\text{p-value} < 0.05 )$: Reject $( H_0)$. The difference in proportions is statistically significant.\n",
    "  - If $( \\text{p-value} \\geq 0.05 )$: Fail to reject $( H_0 )$. The proportions are not significantly different.\n",
    "\n",
    "#### Example Interpretation\n",
    "- Since $( \\text{p-value} = 0.39 > 0.05 )$, fail to reject the null hypothesis. This means there is **no statistically significant difference** between the proportions of successes in the two groups.\n",
    "\n",
    "---\n",
    "\n",
    "### Use Case\n",
    "A two-proportion Z-test is commonly used to:\n",
    "- Compare the success rates of two marketing strategies.\n",
    "- Evaluate the effectiveness of two treatments in a clinical trial.\n",
    "- Analyze proportions in survey responses between two groups.\n",
    "\n",
    "---\n",
    "\n",
    "### Assumptions of the Two-Proportion Z-Test\n",
    "1. **Independence**:\n",
    "   - Observations in each group are independent.\n",
    "   - The two groups are independent of each other.\n",
    "2. **Sufficient Sample Size**:\n",
    "   - Each group must have at least 5 successes and 5 failures ($( \\text{count} )$ and $( \\text{nobs} - \\text{count} ))$.\n",
    "3. **Random Sampling**:\n",
    "   - The samples are randomly selected from the population."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
